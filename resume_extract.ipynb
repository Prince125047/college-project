{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1geqb2H9C6R5rKxpqBtnl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prince125047/college-project/blob/main/resume_extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUDEiZ7IOgvs",
        "outputId": "1fde2730-c383-4839-c68f-846678019707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=a600ad0093277ce38558145e81ad84225b4b894253eac63a46dd1a8df05d8597\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0e/7a/3094a4ceefe657bff7e12dd9592a9d5b6487ef4338ace0afa6\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt, pymupdf\n",
            "Successfully installed docx2txt-0.8 pymupdf-1.25.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf docx2txt pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import fitz  # PyMuPDF for PDFs\n",
        "import docx2txt  # For DOCX\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import json\n",
        "import string\n",
        "\n",
        "# Load pre-trained NLP model (spaCy)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text(\"text\") + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Function to extract text from DOCX\n",
        "def extract_text_from_docx(docx_path):\n",
        "    return docx2txt.process(docx_path)\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Remove punctuation\n",
        "    text = \" \".join(text.split())  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Function to extract technical skills dynamically\n",
        "def extract_technical_skills(text):\n",
        "    tech_skills = {\n",
        "        \"python\", \"java\", \"c++\", \"javascript\", \"sql\", \"html\", \"css\", \"react\", \"node.js\",\n",
        "        \"machine learning\", \"deep learning\", \"tensorflow\", \"pytorch\", \"nlp\", \"opencv\",\n",
        "        \"big data\", \"hadoop\", \"spark\", \"kafka\", \"data science\", \"cloud computing\",\n",
        "        \"aws\", \"azure\", \"gcp\", \"cybersecurity\", \"penetration testing\", \"blockchain\",\n",
        "        \"docker\", \"kubernetes\", \"ci/cd\", \"git\", \"devops\", \"linux\", \"bash scripting\",\n",
        "        \"flask\", \"django\", \"fastapi\", \"ruby\", \"scala\", \"go\", \"rust\", \"typescript\",\n",
        "        \"graphql\", \"postgresql\", \"mongodb\", \"firebase\", \"elasticsearch\", \"redis\",\n",
        "        \"unity\", \"unreal engine\", \"computer vision\", \"llms\", \"prompt engineering\"\n",
        "    }\n",
        "    extracted_skills = set()\n",
        "    doc = nlp(text)\n",
        "    for token in doc:\n",
        "        if token.text.lower() in tech_skills:\n",
        "            extracted_skills.add(token.text.lower())\n",
        "    # Use NLP entity recognition for additional skills\n",
        "    additional_skills = [ent.text for ent in doc.ents if ent.label_ in [\"ORG\", \"PRODUCT\"]]\n",
        "    extracted_skills.update(additional_skills)\n",
        "    return list(extracted_skills)\n",
        "\n",
        "# Function to extract interpersonal skills\n",
        "def extract_interpersonal_skills(text):\n",
        "    soft_skills = {\n",
        "        \"communication\", \"teamwork\", \"leadership\", \"problem-solving\",\n",
        "        \"adaptability\", \"creativity\", \"collaboration\", \"empathy\",\n",
        "        \"time management\", \"critical thinking\", \"negotiation\", \"work ethic\",\n",
        "        \"decision-making\", \"conflict resolution\", \"attention to detail\",\n",
        "        \"emotional intelligence\", \"resilience\", \"public speaking\", \"active listening\",\n",
        "        \"persuasion\", \"networking\", \"mentoring\", \"stress management\"\n",
        "    }\n",
        "    extracted_skills = set()\n",
        "    doc = nlp(text)\n",
        "    for token in doc:\n",
        "        if token.text.lower() in soft_skills:\n",
        "            extracted_skills.add(token.text.lower())\n",
        "    return list(extracted_skills)\n",
        "\n",
        "# Function to extract insights from projects and experience\n",
        "def extract_project_insights(text):\n",
        "    keywords = {\n",
        "        \"developed\", \"built\", \"created\", \"designed\", \"implemented\",\n",
        "        \"analyzed\", \"optimized\", \"deployed\", \"engineered\", \"researched\",\n",
        "        \"integrated\", \"evaluated\", \"refactored\", \"debugged\", \"automated\",\n",
        "        \"tested\", \"configured\", \"launched\", \"prototyped\", \"constructed\",\n",
        "        \"innovated\", \"streamlined\", \"refactored\", \"mentored\", \"led\",\n",
        "        \"collaborated\", \"architected\", \"initiated\", \"pioneered\"\n",
        "    }\n",
        "    insights = []\n",
        "    sentences = text.split(\". \")\n",
        "    for sentence in sentences:\n",
        "        for keyword in keywords:\n",
        "            if keyword in sentence.lower():\n",
        "                insights.append(sentence)\n",
        "                break\n",
        "    return insights\n",
        "\n",
        "# Function to parse resume\n",
        "def parse_resume(file_path, file_type=\"pdf\"):\n",
        "    text = extract_text_from_pdf(file_path) if file_type == \"pdf\" else extract_text_from_docx(file_path)\n",
        "    text = clean_text(text)  # Clean text for better processing\n",
        "    parsed_data = {\n",
        "        \"technical_skills\": extract_technical_skills(text),\n",
        "        \"interpersonal_skills\": extract_interpersonal_skills(text),\n",
        "        \"project_insights\": extract_project_insights(text),\n",
        "        \"cleaned_text\": text  # Fully cleaned text for Word2Vec model\n",
        "    }\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame([parsed_data])\n",
        "\n",
        "    # Convert to JSON\n",
        "    json_data = json.dumps(parsed_data, indent=4)\n",
        "\n",
        "    return df, json_data\n",
        "\n",
        "# Example Usage\n",
        "df_resume, json_resume = parse_resume(\"/content/My Resume (1).pdf\", \"pdf\")\n",
        "print(df_resume)\n",
        "print(json_resume)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCyviMf9X4wT",
        "outputId": "fb646b45-442f-41a8-8f00-c6a5b12db332"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       technical_skills interpersonal_skills  \\\n",
            "0  [python, css, javascript, sql, java]                   []   \n",
            "\n",
            "                                    project_insights  \\\n",
            "0  [rohit kumar software developer eager to solve...   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0  rohit kumar software developer eager to solve ...  \n",
            "{\n",
            "    \"technical_skills\": [\n",
            "        \"python\",\n",
            "        \"css\",\n",
            "        \"javascript\",\n",
            "        \"sql\",\n",
            "        \"java\"\n",
            "    ],\n",
            "    \"interpersonal_skills\": [],\n",
            "    \"project_insights\": [\n",
            "        \"rohit kumar software developer eager to solve real world problem into feasible software solution rohitkr8568gmailcom 916206449606 patna india education btech cse bakhtiyarpur college of enginnering patna 122021 present 805 polytechnic state board of technical education sbte 062016 072019 83 matriculate dav high school patna 042014 062015 83 work experience salesforce developer intern salesforce 122023 022024 patna bihar during my virtual internship at salesforce i mastered key salesforce technologies through handson experience completing over 20 trailhead modules i deepened my understanding of salesforce development and earned multiple certications that showcase my expertise completed 20 salesforce trailhead modules including salesforce fundamentals organizational setup relationship process automation types of flows security apex testing debugging vs code setup cli setup lightning web components lwc api earned 3 super badges apex specialist process automation specialist developer super set fundamental of machine learning with python for business data analytics ybi foundation 012023 022023 skills c c dsa python java css javascript sql personal projects job recommendation web app 122024 032025 developed a job recommendation web app using collaborative \\ufb01ltering and user preferences certificates theory of computation 072024 092024 gained a solid understanding of various models of computation and study their power and limitations the properties of the corresponding language classes de\\ufb01ned by these models and the relations between them problem solving through programming in c 072023 102023 gained a solid understanding of c programming concepts including variables loops arrays functions and data structures enhanced my problemsolving skills by applying these concepts to solve realworld computational problems languages english full professional pro\\ufb01ciency hindi full professional pro\\ufb01ciency interests playing reading travelling listening music achievementstasks\"\n",
            "    ],\n",
            "    \"cleaned_text\": \"rohit kumar software developer eager to solve real world problem into feasible software solution rohitkr8568gmailcom 916206449606 patna india education btech cse bakhtiyarpur college of enginnering patna 122021 present 805 polytechnic state board of technical education sbte 062016 072019 83 matriculate dav high school patna 042014 062015 83 work experience salesforce developer intern salesforce 122023 022024 patna bihar during my virtual internship at salesforce i mastered key salesforce technologies through handson experience completing over 20 trailhead modules i deepened my understanding of salesforce development and earned multiple certications that showcase my expertise completed 20 salesforce trailhead modules including salesforce fundamentals organizational setup relationship process automation types of flows security apex testing debugging vs code setup cli setup lightning web components lwc api earned 3 super badges apex specialist process automation specialist developer super set fundamental of machine learning with python for business data analytics ybi foundation 012023 022023 skills c c dsa python java css javascript sql personal projects job recommendation web app 122024 032025 developed a job recommendation web app using collaborative \\ufb01ltering and user preferences certificates theory of computation 072024 092024 gained a solid understanding of various models of computation and study their power and limitations the properties of the corresponding language classes de\\ufb01ned by these models and the relations between them problem solving through programming in c 072023 102023 gained a solid understanding of c programming concepts including variables loops arrays functions and data structures enhanced my problemsolving skills by applying these concepts to solve realworld computational problems languages english full professional pro\\ufb01ciency hindi full professional pro\\ufb01ciency interests playing reading travelling listening music achievementstasks\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}